---
title: "Class 12 notes and code"
output:
  html_document: default
  pdf_document: default
---


$\\$


```{r setup, include=FALSE}

# install.packages("latex2exp")

library(latex2exp)


options(scipen=999)


knitr::opts_chunk$set(echo = TRUE)

set.seed(123)

```


$\\$


## Overview

 * Parametric hypothesis tests

$\\$


## Part 1: Parametric tests for one mean



#### Part 1a: Parametric test for one mean - The Chips Ahoy! Challenge 


In the mid-1990s a Nabisco marking campaign claimed that there were at least 1000 chips in every bag of Chips Ahoy! cookies. A group of Air Force cadets tested this claim by dissolving the cookies from 42 bags in water and counting the number of chips.

They found: 

 * The average number of chips per bag was $\bar{x}$ = 1261.6
 * The standard deviation of $s$ = 117.6 chips 


Test whether the average number of chips per bag is greater than 1000.  Do the results confirm Nabisco's claim?  


We will use a t-statistic (t-test) to examine this claim, where the t-statistic is given by:


$t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} $ 


$\\$



**Part 1.1** State the null and alternative hypotheses using words and symbols. Also describe the significance level is and denote it with the appropriate symbol. 

$H_0: \mu_0 = 1000$ 
$H_a: \mu_A > 1000$ 

$\\$


**Part 1.2**  Calculate a t-statistic for the observed sample. 


```{r observed_statistic}

# the data collected from 42 bags of chips
x_bar <- 1261.6
s <- 117.6
n <- 42


# calculate the SE and then the t-statistic (obs_stat)
(obs_stat <- (x_bar - 1000)/(s/sqrt(n)))



```


$\\$


**Part 1.3** Identify and plot the null distribution.


```{r df_calculation}



# a conservative estimate of the degrees of freedom
(degree_free <- n - 1)

# plot the null distribution with the observed statistic on it using the dt() function
x_vals <- seq(-20, 20, length.out = 1000)
y_vals <- dt(x_vals, degree_free)

# add a verticle line for the observed statistic
plot(x_vals, y_vals, type = "l")
points(x_vals, rep(0, length(x_vals)), type = 'l')
abline(v = obs_stat, col = "red")

```
$\\$


**Part 1.4** Now calculate the p-value in the R chunk below using the pt() function 

```{r p_value}

(p_val <- pt(obs_stat, df = degree_free, lower.tail = FALSE))




```


$\\$


**Part 1.5** Are the results seem statistical significant? 


$\\$



## Part 2: Parametric tests for comparing two means

**Question:** Does eating late at night make you put on more weight compared to whether you ate the same amount of food during the day? 


To test this idea researchers, [Fonken et al, 2010](https://www.ncbi.nlm.nih.gov/pubmed/20937863), examined this question in mice. 

Mice were randomly divided into 2 groups:

 * **Dark condition**:  8 mice were given 8 hours of darkness at night when they couldn't eat
 * **Light condition**: 9 were constantly exposed to light for 24 hours so they could always eat


The data from the mice is below. Let's use a t-test to see if there is any difference between the amount of weight the mice gained between these two conditions. 


Our formula for a t-statistic for comparing two means is:  $t = \frac{\bar{x_{light}} - \bar{x_{dark}}}{SE} $ 



Our formula for calculating the standard error is: $SE = \sqrt{\frac{s_1^2}{n_2} + \frac{s_2^2}{n_1}}$


This is Welch's t-test, which gives valid results even when there are unequal variances between the two groups. 





$\\$





##### Step 0: Plot the data


```{r mice_plot}

# run this once
# get the mice data
# source('class_functions.R')
# download_class_data("mice.Rda")

# load the data
load("mice.Rda")



# plot the data as a boxplot



# plot the data as a strip chart by


# a) creating a list of the data 



# b) creating a stripchart   



```




##### Step 1: State the null and alternative hypotheses 


$H_0:$
$H_A:$








$\\$







##### Step 2: Calculate the observed statistic

```{r pill_obs_stat}

n1 <- length(light_BM_increase)
n2 <- length(dark_BM_increase)

# calculate the pooled SE
(SE_pooled <- sqrt(  var(light_BM_increase)/n1 + var(dark_BM_increase)/n2   ))

# calculate the observed t-statistic 
(    (mean(light_BM_increase) - mean(dark_BM_increase))/SE_pooled)


```






$\\$






##### Step 3: Create the null distribution



```{r null_dist_mice}



# sample sizes for the two conditions



# a conservative estimate of the degrees of freedom



# plot the null distribution with the observed statistic on it





```






$\\$






##### Step 4: Calculate a p-value


```{r p_value_mice}



# calculate the p-value




```






$\\$







##### Step 5: Make a decision








$\\$







