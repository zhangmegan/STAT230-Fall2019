---
title: "Class 7 notes and code"
output:
  html_document: default
  pdf_document: default
---



$\\$




```{r setup, include=FALSE}

# install.packages("latex2exp")

library(latex2exp)

knitr::opts_chunk$set(echo = TRUE)

set.seed(123)

```



$\\$




## Overview

 * Tips on the homework from the TAs
 * Review/continuation of creating confidence intervals for a proportion
 * Concepts behind a hypothesis test for a single proportion
 * Hypothesis tests for a single proportion in R





$\\$






## Part 1: Tips on future homework

The TAs had a few tips to keep in mind when submitting future homework which are:

* When a problem is computationally fast, make sure to use enough iterations in your for loop (i.e., 10,000 iterations, not 100). As a general rule of thumb, your answer shouldn't change much depending on the starting random number seed. You can get misleading estimate/plots if you have not run enough iterations.

* Make sure to use a reasonable number of histogram bins when describing a distribution's shape (e.g., nclass = 50 not 4).

* Make sure your code is not on one long line which gets cut off when you knit to a pdf, e.g., 

plot(x, y,
     xlab = "my x label",
     ylab = "my y label", 
     main = "the title of my plot")

* 1-2 paragraphs should suffice for most written answers (always < 1 page). 

* When running code interactively, there are useful R Studio features 
    - the broom to clear environment variables
    - the green down arrow to run code up to the current chunk




$\\$





## Part 1: Continuation of formulas for the standard error and CIs for a proportion

For particular statistics, there are formulas that give the standard error! We can use these instead of running the bootstrap when they are available. 



$\\$




#### Part 1.1: Formula for the standard error of the mean $\bar{x}$


When our statistic of interest is the mean $\bar{x}$, the formula to compute the standard error of the mean is:


(1) $\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}$

and an estimate for this is given by:

(2) $s_{\bar{x}} = \frac{s}{\sqrt{n}}$

Where:

* $\sigma$ is the population standard deviation, 
* *s* is the standard deviation statistic computed from a sample of size *n* 
* *n* is the sample size. 

Note, equation 1 above is a theoretical construct since we will never know $\sigma$ (only Plato knows this) while equation 2 above is possible to calculate from a sample of data. 


Let's use formula 2 to calculate the  $s_{\bar{x}}$:


```{r part_5_1}

library(okcupiddata)

the_ages <- profiles$age[1:20]

mean_ages <- mean(the_ages)
n <- length(the_ages)
sd_ages <- sd(the_ages)

(SE_ages <- sd_ages/sqrt(n))


(CI <- mean_ages + SE_ages * c(-2, 2))


```






$\\$






#### Part 1.2: Formula for the standard error of a proportion $\hat{p}$


When our statistic of interest is the sample proportion $\hat{p}$, the formula to compute the standard error of a proportion is:


(1) $\sigma_{\hat{p}} = \sqrt{\frac{\pi (1 - \pi)}{n}}$

and an estimate for this is given by:

(2) $s_{\bar{x}} = \sqrt{\frac{\hat{p} (1 - \hat{p})}{n}}$

Where:

* $\pi$ is the population proportion 
* $\hat{p}$ is the proportion from a sample of size *n* 
* *n* is the sample size. 

Again, equation 1 above is a theoretical construct since we will never know $\pi$ (only Plato knows this) while equation 2 above can be used to calculate from a sample of data. 





$\\$





**Question**: If we have formulas for the standard error of these statistics, why use the bootstrap?  


**Answer:** 

The bootstrap works for many statistics that do not have formulas for their standard errors






$\\$







#### Part 1.3: Bootstrap for CIs for proportions


```{r bootstrap_proportion}

# get drug use behavior for first 50 OkCupid users
(type_of_drug_user_50 <- na.omit(profiles$drugs)[1:50])

# calculate the p-hat statistic for "sometimes" drug users
obs_stat <- prop.table(table(type_of_drug_user_50))
(obs_stat <- obs_stat[2])

# create the bootstrap distribution by creating 10,000 bootstrap statistics
# through sampling with replacement
boot_dist <- NULL
for (i in 1:10000){
  
  boot_sample <- sample(type_of_drug_user_50, replace = TRUE)
  boot_dist[i] <- prop.table(table(boot_sample))[2]
  
}


# plot a histogram of the bootstrap distribution
hist(boot_dist,
     xlab = TeX("$\\hat{p}$"),
     main = TeX("bootstrap distribution of $\\hat{p}$"),
     nclass = 100)


# calculate the 95% CI using the percentile method
quantile(boot_dist, c(.025, .975))

# bootstrap estimate of the standard error, SE*
(boot_SE <- sd(boot_dist))

# calculate the CI using the formula...
(formula_SE <- sqrt(  (obs_stat * (1-obs_stat))/length(type_of_drug_user_50)))

# create the CI using the SE from the formula
obs_stat + 2 * c(-formula_SE , formula_SE )

```


![](https://raw.githubusercontent.com/emeyers/SDS230_F19/master/class_images/class_06/colbert_bootstrap.jpg)







$\\$







## Part 2: Hypothesis tests for a single proportion


Let's start our review of hypothesis tests by examining hypothesis tests for a single proportion $\pi$



$\\$

